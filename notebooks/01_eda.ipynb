{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539c921d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "# Set up Vietnamese font (if available)\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ab15a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "# Try to load from file first, otherwise create from script\n",
    "try:\n",
    "    df = pd.read_csv('../data/raw/initial_data.csv')\n",
    "    print(f\"Loaded dataset from file: {len(df)} samples\")\n",
    "except FileNotFoundError:\n",
    "    print(\"File not found. Creating dataset from script...\")\n",
    "    from data.collect_data import create_initial_dataset, save_dataset_csv\n",
    "    samples = create_initial_dataset()\n",
    "    save_dataset_csv(samples, '../data/raw/initial_data.csv')\n",
    "    df = pd.DataFrame(samples)\n",
    "    print(f\"Created dataset: {len(df)} samples\")\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nDataset Preview:\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda9ebc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"=\" * 50)\n",
    "print(\"üìà DATASET OVERVIEW\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"\\nüìä Total samples: {len(df)}\")\n",
    "print(f\"üìù Columns: {list(df.columns)}\")\n",
    "print(f\"\\nüî¢ Data types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(f\"\\n‚ùì Missing values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e249b54d",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Emotion Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a502f5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emotion distribution\n",
    "emotion_counts = df['primary_emotion'].value_counts()\n",
    "\n",
    "print(\"Emotion Distribution:\")\n",
    "print(emotion_counts)\n",
    "print(f\"\\nTotal unique emotions: {len(emotion_counts)}\")\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bar plot\n",
    "colors = plt.cm.Set3(np.linspace(0, 1, len(emotion_counts)))\n",
    "emotion_counts.plot(kind='bar', ax=axes[0], color=colors, edgecolor='black')\n",
    "axes[0].set_title('Emotion Distribution (Bar Chart)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Emotion')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Add value labels\n",
    "for i, v in enumerate(emotion_counts):\n",
    "    axes[0].text(i, v + 0.5, str(v), ha='center', fontweight='bold')\n",
    "\n",
    "# Pie chart\n",
    "axes[1].pie(emotion_counts, labels=emotion_counts.index, autopct='%1.1f%%', \n",
    "            colors=colors, startangle=90, explode=[0.02]*len(emotion_counts))\n",
    "axes[1].set_title('Emotion Distribution (Pie Chart)', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/eda_emotion_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff1918b",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Intensity Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467a9c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intensity distribution\n",
    "intensity_counts = df['intensity'].value_counts().sort_index()\n",
    "\n",
    "print(\"Intensity Distribution:\")\n",
    "print(intensity_counts)\n",
    "print(f\"\\nMean intensity: {df['intensity'].mean():.2f}\")\n",
    "print(f\"Median intensity: {df['intensity'].median():.2f}\")\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bar plot\n",
    "intensity_labels = ['Very Weak', 'Weak', 'Medium', 'Strong', 'Very Strong']\n",
    "colors = plt.cm.RdYlGn(np.linspace(0.2, 0.8, 5))\n",
    "intensity_counts.plot(kind='bar', ax=axes[0], color=colors, edgecolor='black')\n",
    "axes[0].set_title('Intensity Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Intensity Level')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_xticklabels(intensity_labels, rotation=45)\n",
    "\n",
    "# Add value labels\n",
    "for i, v in enumerate(intensity_counts):\n",
    "    axes[0].text(i, v + 0.5, str(v), ha='center', fontweight='bold')\n",
    "\n",
    "# Box plot by emotion\n",
    "df.boxplot(column='intensity', by='primary_emotion', ax=axes[1])\n",
    "axes[1].set_title('Intensity by Emotion', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Emotion')\n",
    "axes[1].set_ylabel('Intensity')\n",
    "plt.suptitle('')  # Remove automatic title\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/eda_intensity_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473a8a31",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Text Length Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876395f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add text length columns\n",
    "df['text_length_chars'] = df['text'].apply(len)\n",
    "df['text_length_words'] = df['text'].apply(lambda x: len(x.split()))\n",
    "\n",
    "print(\"Text Length Statistics:\")\n",
    "print(f\"\\nCharacters:\")\n",
    "print(f\"  Min: {df['text_length_chars'].min()}\")\n",
    "print(f\"  Max: {df['text_length_chars'].max()}\")\n",
    "print(f\"  Mean: {df['text_length_chars'].mean():.1f}\")\n",
    "print(f\"  Median: {df['text_length_chars'].median():.1f}\")\n",
    "\n",
    "print(f\"\\nWords:\")\n",
    "print(f\"  Min: {df['text_length_words'].min()}\")\n",
    "print(f\"  Max: {df['text_length_words'].max()}\")\n",
    "print(f\"  Mean: {df['text_length_words'].mean():.1f}\")\n",
    "print(f\"  Median: {df['text_length_words'].median():.1f}\")\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram - Characters\n",
    "axes[0].hist(df['text_length_chars'], bins=20, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "axes[0].axvline(df['text_length_chars'].mean(), color='red', linestyle='--', label=f\"Mean: {df['text_length_chars'].mean():.1f}\")\n",
    "axes[0].set_title('Text Length Distribution (Characters)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Number of Characters')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].legend()\n",
    "\n",
    "# Histogram - Words\n",
    "axes[1].hist(df['text_length_words'], bins=15, color='coral', edgecolor='black', alpha=0.7)\n",
    "axes[1].axvline(df['text_length_words'].mean(), color='red', linestyle='--', label=f\"Mean: {df['text_length_words'].mean():.1f}\")\n",
    "axes[1].set_title('Text Length Distribution (Words)', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Number of Words')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/eda_text_length.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3a1d7c",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Emoji Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e474b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all emojis\n",
    "all_emojis = []\n",
    "for col in ['emoji_1', 'emoji_2', 'emoji_3']:\n",
    "    if col in df.columns:\n",
    "        emojis = df[col].dropna().tolist()\n",
    "        all_emojis.extend(emojis)\n",
    "\n",
    "emoji_freq = Counter(all_emojis)\n",
    "\n",
    "print(f\"Total emoji occurrences: {len(all_emojis)}\")\n",
    "print(f\"Unique emojis: {len(emoji_freq)}\")\n",
    "print(f\"\\nTop 20 Most Common Emojis:\")\n",
    "for emoji, count in emoji_freq.most_common(20):\n",
    "    print(f\"  {emoji}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc666240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emoji visualization\n",
    "top_20 = emoji_freq.most_common(20)\n",
    "emojis = [e[0] for e in top_20]\n",
    "counts = [e[1] for e in top_20]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "colors = plt.cm.viridis(np.linspace(0, 0.8, len(emojis)))\n",
    "bars = ax.barh(range(len(emojis)), counts, color=colors, edgecolor='black')\n",
    "\n",
    "ax.set_yticks(range(len(emojis)))\n",
    "ax.set_yticklabels(emojis, fontsize=16)\n",
    "ax.invert_yaxis()  # Largest at top\n",
    "\n",
    "ax.set_title('Top 20 Most Common Emojis', fontsize=16, fontweight='bold')\n",
    "ax.set_xlabel('Frequency', fontsize=12)\n",
    "\n",
    "# Add value labels\n",
    "for i, v in enumerate(counts):\n",
    "    ax.text(v + 0.5, i, str(v), va='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/eda_emoji_frequency.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1343f8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emoji distribution by emotion\n",
    "emoji_by_emotion = {}\n",
    "\n",
    "for emotion in df['primary_emotion'].unique():\n",
    "    emotion_df = df[df['primary_emotion'] == emotion]\n",
    "    emojis = []\n",
    "    for col in ['emoji_1', 'emoji_2', 'emoji_3']:\n",
    "        if col in emotion_df.columns:\n",
    "            emojis.extend(emotion_df[col].dropna().tolist())\n",
    "    emoji_by_emotion[emotion] = Counter(emojis).most_common(5)\n",
    "\n",
    "print(\"Top 5 Emojis by Emotion:\")\n",
    "print(\"=\" * 50)\n",
    "for emotion, top_emojis in sorted(emoji_by_emotion.items()):\n",
    "    emoji_str = \" \".join([f\"{e}({c})\" for e, c in top_emojis])\n",
    "    print(f\"{emotion.capitalize():15} ‚Üí {emoji_str}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f78f6e",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Emotion-Intensity Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16eaaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create heatmap\n",
    "pivot = pd.crosstab(df['primary_emotion'], df['intensity'])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "sns.heatmap(pivot, annot=True, fmt='d', cmap='YlOrRd', \n",
    "            linewidths=0.5, ax=ax, cbar_kws={'label': 'Count'})\n",
    "\n",
    "ax.set_title('Emotion vs Intensity Distribution', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Intensity Level', fontsize=12)\n",
    "ax.set_ylabel('Emotion', fontsize=12)\n",
    "\n",
    "# Set intensity labels\n",
    "intensity_labels = ['Very Weak', 'Weak', 'Medium', 'Strong', 'Very Strong']\n",
    "ax.set_xticklabels(intensity_labels, rotation=45, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/eda_emotion_intensity_heatmap.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed07d72a",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Sample Texts by Emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed30133a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample texts for each emotion\n",
    "print(\"Sample Texts by Emotion:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for emotion in sorted(df['primary_emotion'].unique()):\n",
    "    print(f\"\\nüè∑Ô∏è {emotion.upper()}\")\n",
    "    print(\"-\" * 40)\n",
    "    samples = df[df['primary_emotion'] == emotion].sample(min(3, len(df[df['primary_emotion'] == emotion])))\n",
    "    for _, row in samples.iterrows():\n",
    "        emojis = f\"{row['emoji_1']} {row.get('emoji_2', '')} {row.get('emoji_3', '')}\".strip()\n",
    "        print(f\"  \\\"{row['text']}\\\" ‚Üí {emojis} (intensity: {row['intensity']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de76f3be",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b7761a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary report\n",
    "print(\"=\" * 60)\n",
    "print(\"üìä EDA SUMMARY REPORT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nüìÅ Dataset Size: {len(df)} samples\")\n",
    "print(f\"\\nüé≠ Emotions: {len(df['primary_emotion'].unique())} unique\")\n",
    "for emotion, count in emotion_counts.items():\n",
    "    pct = count / len(df) * 100\n",
    "    print(f\"   - {emotion}: {count} ({pct:.1f}%)\")\n",
    "\n",
    "print(f\"\\nüìà Intensity:\")\n",
    "print(f\"   - Mean: {df['intensity'].mean():.2f}\")\n",
    "print(f\"   - Mode: {df['intensity'].mode().values[0]}\")\n",
    "\n",
    "print(f\"\\nüìù Text Length:\")\n",
    "print(f\"   - Avg words: {df['text_length_words'].mean():.1f}\")\n",
    "print(f\"   - Avg chars: {df['text_length_chars'].mean():.1f}\")\n",
    "\n",
    "print(f\"\\nüòä Emojis:\")\n",
    "print(f\"   - Unique emojis: {len(emoji_freq)}\")\n",
    "print(f\"   - Top 5: {' '.join([e for e, _ in emoji_freq.most_common(5)])}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Dataset Quality:\")\n",
    "missing = df.isnull().sum().sum()\n",
    "print(f\"   - Missing values: {missing}\")\n",
    "print(f\"   - Data complete: {'Yes ‚úì' if missing == 0 else 'No ‚úó'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c9a3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save summary to file\n",
    "summary = {\n",
    "    'total_samples': len(df),\n",
    "    'unique_emotions': len(df['primary_emotion'].unique()),\n",
    "    'emotion_counts': dict(emotion_counts),\n",
    "    'intensity_mean': df['intensity'].mean(),\n",
    "    'avg_text_words': df['text_length_words'].mean(),\n",
    "    'avg_text_chars': df['text_length_chars'].mean(),\n",
    "    'unique_emojis': len(emoji_freq),\n",
    "    'top_10_emojis': dict(emoji_freq.most_common(10)),\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('../data/eda_summary.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(summary, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"\\n‚úì Summary saved to data/eda_summary.json\")\n",
    "print(\"‚úì Plots saved to data/eda_*.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbb761a",
   "metadata": {},
   "source": [
    "---\n",
    "## üìã Key Insights\n",
    "\n",
    "### Observations:\n",
    "1. **Dataset Balance**: Check if emotions are evenly distributed\n",
    "2. **Text Length**: Most texts are short (< 10 words) - typical for chat messages\n",
    "3. **Intensity**: Strong emotions (4-5) are common\n",
    "4. **Top Emojis**: üòä, üéâ, üò¢, üíî are most frequent\n",
    "\n",
    "### Recommendations:\n",
    "1. May need to augment underrepresented emotions\n",
    "2. Short texts = need efficient preprocessing\n",
    "3. Top 20 emojis cover ~80% of use cases - focus on these first\n",
    "\n",
    "### Next Steps:\n",
    "- [ ] Expand dataset to 300 samples\n",
    "- [ ] Implement baseline models\n",
    "- [ ] Calculate inter-rater agreement"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
